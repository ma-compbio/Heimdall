{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5076ec1-f123-46b3-a92c-eec1f3acf6fe",
   "metadata": {},
   "source": [
    "# Implementing a novel scFM tokenizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f94504-650b-470b-bb51-32c712d9f7aa",
   "metadata": {},
   "source": [
    "Beyond benchmarking existing tokenizers, <span style=\"font-variant:small-caps; font-size: 16px\">Heimdall</span> also enables users to introduce, evaluate and share novel tokenizer designs. Here, we demonstrate several examples of this. As in the first demo, we use a subset of the [**scTab** dataset](https://www.nature.com/articles/s41467-024-51059-5) for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53af211e-cacc-4b91-ab85-57a6703aece1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T14:42:45.700437Z",
     "iopub.status.busy": "2025-11-25T14:42:45.700318Z",
     "iopub.status.idle": "2025-11-25T14:42:45.829344Z",
     "shell.execute_reply": "2025-11-25T14:42:45.828748Z",
     "shell.execute_reply.started": "2025-11-25T14:42:45.700425Z"
    }
   },
   "outputs": [],
   "source": [
    "import hydra\n",
    "import Heimdall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0460b09-04fa-4b5b-83fe-3a77f3190a1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T14:42:45.830796Z",
     "iopub.status.busy": "2025-11-25T14:42:45.830146Z",
     "iopub.status.idle": "2025-11-25T14:42:50.528302Z",
     "shell.execute_reply": "2025-11-25T14:42:50.527062Z",
     "shell.execute_reply.started": "2025-11-25T14:42:45.830780Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97a8d119-d4a9-4e7d-8d8f-96e5de18b30f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T14:42:50.530105Z",
     "iopub.status.busy": "2025-11-25T14:42:50.529330Z",
     "iopub.status.idle": "2025-11-25T14:42:56.915837Z",
     "shell.execute_reply": "2025-11-25T14:42:56.914987Z",
     "shell.execute_reply.started": "2025-11-25T14:42:50.530087Z"
    }
   },
   "outputs": [],
   "source": [
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de731a8-f86a-48f1-9a9e-f602c2446607",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T14:42:56.917856Z",
     "iopub.status.busy": "2025-11-25T14:42:56.916864Z",
     "iopub.status.idle": "2025-11-25T14:42:57.241249Z",
     "shell.execute_reply": "2025-11-25T14:42:57.240218Z",
     "shell.execute_reply.started": "2025-11-25T14:42:56.917839Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "sc.set_figure_params(figsize=(6, 6), frameon=False)\n",
    "sns.set_theme(style=\"white\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544a3d79-e3c8-44b6-948c-c90fc1eb00c4",
   "metadata": {},
   "source": [
    "We are interested in implementing various popular tokenizers for single-cell foundation models within a standardized framework, which enables us to isolate the impact of the tokenizer _itself_ on downstream performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa7a31-aeaa-45f9-9e5a-1d42b2292fff",
   "metadata": {},
   "source": [
    "## Recap: <span style=\"font-variant:small-caps; font-size: 28px\">Heimdall</span> modularizes scFM tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea75a55-207c-4b33-9079-c2bfe332d87a",
   "metadata": {},
   "source": [
    "The key to <span style=\"font-variant:small-caps; font-size: 16px\">Heimdall</span>'s modularity is the compartmentalization of the tokenizer into $F_\\textbf{G}$, $F_\\textbf{E}$ and $F_\\textbf{C}$ components. Thus, to implement a novel "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d6734-9582-451f-b9ae-0c05d94f7769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:30:48.258581Z",
     "iopub.status.busy": "2025-11-18T12:30:48.258382Z",
     "iopub.status.idle": "2025-11-18T12:30:48.262323Z",
     "shell.execute_reply": "2025-11-18T12:30:48.261616Z",
     "shell.execute_reply.started": "2025-11-18T12:30:48.258564Z"
    }
   },
   "source": [
    "<figure>\n",
    "  <img src=\"../_static/scfm_breakdown.png\"/>\n",
    "  <figcaption><b>Fig 1C (bottom).</b> Application of <span style=\"font-variant:small-caps; font-size: 16px\">Heimdall</span> for systematic design and evaluation of scFMs. The highlighted yellow rectangle indicates introduction of a novel $F_\\textbf{E}$, thereby constituting a new tokenizer implementation. </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e3fca-6004-415a-b06a-c72fceb6e3fb",
   "metadata": {},
   "source": [
    "## Implementing a new $F_\\textbf{G}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c45960-25f5-4560-9f42-6c043af36e75",
   "metadata": {},
   "source": [
    "In our experiments, we use [HyenaDNA](https://arxiv.org/abs/2306.15794) to create a novel gene-identity encoding module. In particular, we feed the DNA sequence of the gene to the HyenaDNA model, and save the outputs as a Torch Tensor file. We already provide a base class that loads the gene embeddings from a `.pt` file, so the implementation is straightforward after we have extracted the embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ce64c-1e70-4d05-b57a-d2bcd212bf5e",
   "metadata": {},
   "source": [
    "### Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56e96d2c-c100-4919-abeb-c850a36a78cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T14:43:47.658089Z",
     "iopub.status.busy": "2025-11-25T14:43:47.657887Z",
     "iopub.status.idle": "2025-11-25T14:43:47.662566Z",
     "shell.execute_reply": "2025-11-25T14:43:47.662010Z",
     "shell.execute_reply.started": "2025-11-25T14:43:47.658072Z"
    }
   },
   "outputs": [],
   "source": [
    "from Heimdall.fg import PretrainedFg\n",
    "class TorchTensorFg(PretrainedFg):   # This is actually already provided in `Heimdall.fg`\n",
    "    \"\"\"Mapping of gene names to pretrained embeddings stored as PyTorch                         \n",
    "    tensors.\"\"\"                                                                                 \n",
    "                                                                                                \n",
    "    def load_embeddings(self):                                                                  \n",
    "        raw_gene_embedding_map = torch.load(self.embedding_filepath, weights_only=True)\n",
    "        \n",
    "        raw_gene_embedding_map = {                                                              \n",
    "            gene_name: embedding.detach().cpu().numpy() for gene_name, embedding in raw_gene_embedding_map.items()\n",
    "        }                                                                                       \n",
    "                                                                                                \n",
    "        return raw_gene_embedding_map  \n",
    "\n",
    "class HyenaDNAFg(TorchTensorFg):\n",
    "    \"\"\"Mapping of gene names to pretrained HyenaDNA embeddings.\"\"\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba03e03-37e3-4153-8fbe-72ed3169869e",
   "metadata": {},
   "source": [
    "### `fg/hyenadna.yaml` config\n",
    "The final step is to write a config file for this $F_\\textbf{G}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa5ebc1d-772b-4f62-8561-f013a1fe1ade",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "```yaml\n",
    "type: Heimdall.fg.HyenaDNAFg                                                                                                                                                                                                                         \n",
    "                                                                                                \n",
    "args:                                                                                           \n",
    "  embedding_parameters:                                                                         \n",
    "    type: Heimdall.embedding.FlexibleTypeEmbedding                                              \n",
    "    constructor: from_pretrained                                                                \n",
    "    args:                                                                                       \n",
    "      embeddings: gene_embeddings                                                               \n",
    "  embedding_filepath: ${data_path}/pretrained_embeddings/hyenaDNA.pt                     \n",
    "  d_embedding: ${model.args.d_model}                                                            \n",
    "  frozen: true \n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed499448-7af9-430c-97b8-9dfa04faa2ac",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e1ac94-9934-41be-af19-d514e78d46be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "with hydra.initialize(version_base=None, config_path=\"../Heimdall/config\"):\n",
    "    config = hydra.compose(\n",
    "        config_name=\"config\",\n",
    "        overrides=[\n",
    "            \"+experiments=sctab_split1_all\",\n",
    "            \"fg=hyenadna\",\n",
    "            \"fe=zero\",\n",
    "            \"fc=geneformer\",\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    OmegaConf.resolve(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd499e6d-8dde-4091-9f73-6c42e5c617df",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73e975cb-04c3-4bfa-bca4-088903f526dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:13:41.859611Z",
     "iopub.status.busy": "2025-11-18T17:13:41.859328Z",
     "iopub.status.idle": "2025-11-18T17:13:41.862818Z",
     "shell.execute_reply": "2025-11-18T17:13:41.862278Z",
     "shell.execute_reply.started": "2025-11-18T17:13:41.859596Z"
    }
   },
   "outputs": [],
   "source": [
    "from Heimdall.trainer import setup_trainer\n",
    "def training_loop(config):\n",
    "    trainer = setup_trainer(config, cpu=config.trainer.cpu)\n",
    "    if trainer is not None:\n",
    "        trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86e4a463-3930-4dfd-b303-135891b9419c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:13:42.214120Z",
     "iopub.status.busy": "2025-11-18T17:13:42.213923Z",
     "iopub.status.idle": "2025-11-18T17:13:42.216450Z",
     "shell.execute_reply": "2025-11-18T17:13:42.215883Z",
     "shell.execute_reply.started": "2025-11-18T17:13:42.214104Z"
    }
   },
   "outputs": [],
   "source": [
    "from accelerate import notebook_launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da8625f-40f5-4be9-899c-77663ccb0711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = (config,)\n",
    "notebook_launcher(training_loop, args, num_processes=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:flash_attn_py312]",
   "language": "python",
   "name": "conda-env-flash_attn_py312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
